{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b16aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: versioned-hdf5 in /tmp/home_dir/.local/lib/python3.8/site-packages (1.3.6)\n",
      "Requirement already satisfied: h5py in /tmp/home_dir/.local/lib/python3.8/site-packages (from versioned-hdf5) (3.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from versioned-hdf5) (1.21.4)\n",
      "Requirement already satisfied: ndindex>=1.5.1 in /tmp/home_dir/.local/lib/python3.8/site-packages (from versioned-hdf5) (1.5.2)\n",
      "Requirement already satisfied: sympy in /tmp/home_dir/.local/lib/python3.8/site-packages (from ndindex>=1.5.1->versioned-hdf5) (1.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /tmp/home_dir/.local/lib/python3.8/site-packages (from sympy->ndindex>=1.5.1->versioned-hdf5) (1.2.1)\n",
      "Requirement already up-to-date: tqdm in /tmp/home_dir/.local/lib/python3.8/site-packages (4.62.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /tmp/home_dir/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already up-to-date: dill in /tmp/home_dir/.local/lib/python3.8/site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "# apt-get install libhdf5-dev\n",
    "#! pip install --user --upgrade pip setuptools wheel\n",
    "! pip install --user versioned-hdf5\n",
    "! pip install --user tqdm --upgrade\n",
    "! pip install torchsummary\n",
    "! pip install --user dill --upgrade\n",
    "#! pip install --user h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "written-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some general modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3850162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "# Select which GPU to use (if available)\n",
    "gpu = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.device(gpu)\n",
    "    print(\"Using GPU %d\" % gpu)\n",
    "else:\n",
    "    gpu = None\n",
    "    print(\"Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-paragraph",
   "metadata": {},
   "source": [
    "# Model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "motivated-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import IntBias\n",
    "from brevitas.inject.enum import ScalingImplType\n",
    "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = \"VGG10exp_2d_w4a4_v2\"\n",
    "\n",
    "path_trained = \"models/\" + model_name + \"_trained.pth\"\n",
    "export_model_filename = \"models/\" + model_name + \"_export.onnx\"\n",
    "ready_model_filename = \"models/\" + model_name + \"_ready.onnx\"\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, trial=None):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Adjustable hyperparameters\n",
    "        input_bits = 8\n",
    "        a_bits = 4\n",
    "        w_bits = 4\n",
    "        filters_conv = 128\n",
    "        filters_dense = 128\n",
    "        input_quant_range = 2\n",
    "\n",
    "        class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
    "            min_val = -input_quant_range\n",
    "            max_val = input_quant_range\n",
    "            scaling_impl_type = ScalingImplType.CONST\n",
    "            bit_width = input_bits\n",
    "\n",
    "        self.core = nn.Sequential(\n",
    "            qnn.QuantHardTanh(act_quant=InputQuantizer, return_quant_tensor=True), # input quantization\n",
    "            \n",
    "            qnn.QuantConv2d(2, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "            nn.BatchNorm2d(filters_conv),\n",
    "            qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "            #nn.MaxPool2d(2),\n",
    "\n",
    "            qnn.QuantConv2d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "            nn.BatchNorm2d(filters_conv),\n",
    "            qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            qnn.QuantConv2d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "            nn.BatchNorm2d(filters_conv),\n",
    "            qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "            #nn.MaxPool2d(2),\n",
    "\n",
    "            qnn.QuantConv2d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits,bias=False),\n",
    "            nn.BatchNorm2d(filters_conv),\n",
    "            qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "\n",
    "            qnn.QuantLinear(int(filters_conv*8*8), filters_dense, weight_bit_width=w_bits, bias=False),\n",
    "            nn.BatchNorm1d(filters_dense),\n",
    "            qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "\n",
    "            qnn.QuantLinear(filters_dense, 24, weight_bit_width=w_bits, bias=True, bias_quant=IntBias),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.reshape(-1,2,int(1024/interleave),int(interleave))\n",
    "        #x = x.permute(0,1,3,2).contiguous()\n",
    "        x = x.reshape(-1,2,32,32)\n",
    "        x = self.core(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NON-Brevitas model for TensorRT/AIE\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "model_name = \"VGG10_TensorRT\"\n",
    "\n",
    "path_trained = \"models/\" + model_name + \"_trained.pth\"\n",
    "export_model_filename = \"models/\" + model_name + \"_export.onnx\"\n",
    "ready_model_filename = \"models/\" + model_name + \"_ready.onnx\"\n",
    "\n",
    "filters_conv = 64\n",
    "filters_dense = 128\n",
    "        \n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(2, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(filters_conv*8, filters_dense, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(filters_dense, filters_dense, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(filters_dense, 24, bias=True),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "x = torch.randn(1, 2, 1024)\n",
    "summary(model, (2,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a92ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1024]             384\n",
      "       BatchNorm1d-2             [-1, 64, 1024]             128\n",
      "              ReLU-3             [-1, 64, 1024]               0\n",
      "         MaxPool1d-4              [-1, 64, 512]               0\n",
      "            Conv1d-5              [-1, 64, 512]          12,288\n",
      "       BatchNorm1d-6              [-1, 64, 512]             128\n",
      "              ReLU-7              [-1, 64, 512]               0\n",
      "         MaxPool1d-8              [-1, 64, 256]               0\n",
      "            Conv1d-9              [-1, 64, 256]          12,288\n",
      "      BatchNorm1d-10              [-1, 64, 256]             128\n",
      "             ReLU-11              [-1, 64, 256]               0\n",
      "        MaxPool1d-12              [-1, 64, 128]               0\n",
      "           Conv1d-13              [-1, 64, 128]          12,288\n",
      "      BatchNorm1d-14              [-1, 64, 128]             128\n",
      "             ReLU-15              [-1, 64, 128]               0\n",
      "        MaxPool1d-16               [-1, 64, 64]               0\n",
      "           Conv1d-17               [-1, 64, 64]          12,288\n",
      "      BatchNorm1d-18               [-1, 64, 64]             128\n",
      "             ReLU-19               [-1, 64, 64]               0\n",
      "        MaxPool1d-20               [-1, 64, 32]               0\n",
      "           Conv1d-21               [-1, 64, 32]          12,288\n",
      "      BatchNorm1d-22               [-1, 64, 32]             128\n",
      "             ReLU-23               [-1, 64, 32]               0\n",
      "        MaxPool1d-24               [-1, 64, 16]               0\n",
      "           Conv1d-25               [-1, 64, 16]          12,288\n",
      "      BatchNorm1d-26               [-1, 64, 16]             128\n",
      "             ReLU-27               [-1, 64, 16]               0\n",
      "        MaxPool1d-28                [-1, 64, 8]               0\n",
      "          Flatten-29                  [-1, 512]               0\n",
      "        Unflatten-30               [-1, 512, 1]               0\n",
      "           Conv1d-31               [-1, 128, 1]          65,536\n",
      "      BatchNorm1d-32               [-1, 128, 1]             256\n",
      "             ReLU-33               [-1, 128, 1]               0\n",
      "           Conv1d-34               [-1, 128, 1]          16,384\n",
      "      BatchNorm1d-35               [-1, 128, 1]             256\n",
      "             ReLU-36               [-1, 128, 1]               0\n",
      "           Conv1d-37                [-1, 24, 1]           3,096\n",
      "          Flatten-38                   [-1, 24]               0\n",
      "       LogSoftmax-39                   [-1, 24]               0\n",
      "================================================================\n",
      "Total params: 160,536\n",
      "Trainable params: 160,536\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.49\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 4.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#NON-Brevitas model for AIE (no linear layer)\n",
    "from torch import nn\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "model_name = \"VGG10_TensorRT\"\n",
    "\n",
    "path_trained = \"models/\" + model_name + \"_trained.pth\"\n",
    "export_model_filename = \"models/\" + model_name + \"_export.onnx\"\n",
    "ready_model_filename = \"models/\" + model_name + \"_ready.onnx\"\n",
    "\n",
    "filters_conv = 64\n",
    "filters_dense = 128\n",
    "        \n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(2, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    nn.Conv1d(filters_conv, filters_conv, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    # flatten into C dimension, L=1\n",
    "    nn.Flatten(),\n",
    "    nn.Unflatten(1, (filters_conv*8, 1)),\n",
    "\n",
    "    nn.Conv1d(filters_conv*8, filters_dense, 1, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv1d(filters_dense, filters_dense, 1, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv1d(filters_dense, 24, 1, bias=True),\n",
    "    nn.Flatten(),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "summary(model, (2,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ac859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINED MODEL FROM DETERMINED.AI\n",
    "from torch import nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import IntBias\n",
    "from brevitas.inject.enum import ScalingImplType\n",
    "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = \"18_VGG10_w3a3_v2\"\n",
    "\n",
    "path_trained = \"models/\" + model_name + \"_trained.pth\"\n",
    "export_model_filename = \"models/\" + model_name + \"_export.onnx\"\n",
    "ready_model_filename = \"models/\" + model_name + \"_ready.onnx\"\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, trial=None):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        dropout_conv = 0\n",
    "        dropout_dense = 0\n",
    "        input_bits = 8\n",
    "        a_bits = 3\n",
    "        w_bits = 3\n",
    "        a_bits_first = 3\n",
    "        w_bits_first = 3\n",
    "        filters_conv = 64\n",
    "        filters_dense = 128\n",
    "        channelwise_w_scaling = True\n",
    "        remove_dense_layer = False\n",
    "        input_quant_range = 2.0\n",
    "        \n",
    "        class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
    "            min_val = -input_quant_range\n",
    "            max_val = input_quant_range\n",
    "            scaling_impl_type = ScalingImplType.CONST\n",
    "            bit_width = input_bits\n",
    "\n",
    "        self.core = nn.Sequential(\n",
    "            qnn.QuantHardTanh(act_quant=InputQuantizer, return_quant_tensor=True), # input quantization\n",
    "            qnn.QuantConv1d(2, filters_conv, 3, padding=1, weight_bit_width=w_bits_first, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            #qnn.QuantReLU(bit_width=a_bits_first, return_quant_tensor=True),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits_first, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            #qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "\n",
    "            qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling, bias=False), #1x3 kernel, pad by 1 on each side\n",
    "            nn.BatchNorm1d(filters_conv),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout2d(dropout_conv),\n",
    "\n",
    "            qnn.QuantMaxPool1d(2),\n",
    "            nn.Flatten(),\n",
    "\n",
    "            qnn.QuantLinear(filters_conv*8, filters_dense, bias=False, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling),\n",
    "            nn.BatchNorm1d(filters_dense),\n",
    "            qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "            nn.Dropout(dropout_dense),\n",
    "        )\n",
    "\n",
    "        if remove_dense_layer:\n",
    "            self.final_layers = nn.Sequential(\n",
    "                qnn.QuantLinear(filters_dense, 24, bias=True, weight_bit_width=w_bits, weight_scaling_per_output_channel=False, bias_quant=IntBias),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "\n",
    "            )\n",
    "        else:\n",
    "            self.final_layers = nn.Sequential(\n",
    "                qnn.QuantLinear(filters_dense, filters_dense, bias=False, weight_bit_width=w_bits, weight_scaling_per_output_channel=channelwise_w_scaling),\n",
    "                nn.BatchNorm1d(filters_dense),\n",
    "                qnn.QuantHardTanh(bit_width=a_bits, max_val=1.0, min_val=-1.0, return_quant_tensor=True),\n",
    "                nn.Dropout(dropout_dense),\n",
    "\n",
    "                qnn.QuantLinear(filters_dense, 24, bias=True, weight_bit_width=w_bits, weight_scaling_per_output_channel=False, bias_quant=IntBias),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0,2,1).contiguous() #convert to NCL (-1,2,1024)\n",
    "        x = self.core(x)\n",
    "        x = self.final_layers(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-chrome",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17304cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if dataset is present\n",
    "import os.path\n",
    "dataset_path = \"/home/felixj/WD/datasets/RadioML/2018/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "os.path.isfile(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "happy-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "\n",
    "class radioml_18_dataset(Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        super(radioml_18_dataset, self).__init__()\n",
    "        h5_file = h5py.File(dataset_path,'r')\n",
    "        self.data = h5_file['X']\n",
    "        self.mod = np.argmax(h5_file['Y'], axis=1) # comes in one-hot encoding\n",
    "        self.snr = h5_file['Z'][:,0]\n",
    "        self.len = self.data.shape[0]\n",
    "\n",
    "        self.mod_classes = ['OOK','4ASK','8ASK','BPSK','QPSK','8PSK','16PSK','32PSK',\n",
    "        '16APSK','32APSK','64APSK','128APSK','16QAM','32QAM','64QAM','128QAM','256QAM',\n",
    "        'AM-SSB-WC','AM-SSB-SC','AM-DSB-WC','AM-DSB-SC','FM','GMSK','OQPSK']\n",
    "        self.snr_classes = np.arange(-20., 32., 2) # -20dB to 30dB\n",
    "\n",
    "        # do not touch this seed to ensure the prescribed train/test split!\n",
    "        np.random.seed(2018)\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        for mod in range(0, 24): # all modulations (0 to 23)\n",
    "            for snr_idx in range(0, 26): # all SNRs (0 to 25 = -20dB to +30dB)\n",
    "                # 'X' holds frames strictly ordered by modulation and SNR\n",
    "                start_idx = 26*4096*mod + 4096*snr_idx\n",
    "                indices_subclass = list(range(start_idx, start_idx+4096))\n",
    "                \n",
    "                # 90%/10% training/test split, applied evenly for each mod-SNR pair\n",
    "                split = int(np.ceil(0.1 * 4096)) \n",
    "                np.random.shuffle(indices_subclass)\n",
    "                train_indices_subclass = indices_subclass[split:]\n",
    "                test_indices_subclass = indices_subclass[:split]\n",
    "                \n",
    "                # train on >= -6 dB\n",
    "                if snr_idx >= 7:\n",
    "                # short training for test\n",
    "                #if snr_idx >=25:\n",
    "                    train_indices.extend(train_indices_subclass)\n",
    "                test_indices.extend(test_indices_subclass)\n",
    "                \n",
    "        self.train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "        self.test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # transpose frame into Pytorch channels-first format (NCL = -1,2,1024)\n",
    "        return self.data[idx].transpose(), self.mod[idx], self.snr[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = radioml_18_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-garage",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "passive-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "\n",
    "    for (inputs, target, snr) in tqdm(train_loader, desc=\"Batches\", leave=False):   \n",
    "        if gpu is not None:\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "           \n",
    "    return losses\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for (inputs, target, snr) in test_loader:\n",
    "            if gpu is not None:\n",
    "                inputs = inputs.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(inputs)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323ccc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed5dccfe7e546eaaea5fab889fa1779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss = 1.010981, test accuracy = 0.374945\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 1\n",
    "\n",
    "data_loader_train = DataLoader(dataset, batch_size=batch_size, sampler=dataset.train_sampler)\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler=dataset.test_sampler)\n",
    "\n",
    "if gpu is not None:\n",
    "    model = model.cuda()\n",
    "\n",
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if gpu is not None:\n",
    "    criterion = criterion.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
    "        test_acc = test(model, data_loader_test)\n",
    "        print(\"Epoch %d: Training loss = %f, test accuracy = %f\" % (epoch, np.mean(loss_epoch), test_acc))\n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "977adfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss over epochs\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be8c8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot test accuracy over epochs\n",
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "367b7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained parameters to disk\n",
    "torch.save(model.state_dict(), path_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e9892",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de952dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained parameters\n",
    "savefile = \"models/18_VGG10_w3a3_v2/state_dict.pth\"\n",
    "saved_state = torch.load(savefile, map_location=torch.device(\"cpu\"))\n",
    "#model.load_state_dict(saved_state)\n",
    "model.load_state_dict(saved_state['models_state_dict'][0])\n",
    "if gpu is not None:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-blame",
   "metadata": {},
   "source": [
    "# Export to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "welcome-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/18_VGG10_w3a3_v2_export.onnx\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_shape = (1, 2, 1024)\n",
    "\n",
    "# old export style:\n",
    "from brevitas.export import FINNManager\n",
    "FINNManager.export(model.cpu(), input_shape=input_shape, export_path=export_model_filename)\n",
    "\n",
    "# create a QuantTensor instance to mark input as INT8 during export\n",
    "#import brevitas.onnx as bo\n",
    "#from brevitas.quant_tensor import QuantTensor\n",
    "#input_a = np.random.randint(0, 8, size=input_shape).astype(np.float32)\n",
    "#scale = 1.0\n",
    "#input_t = torch.from_numpy(input_a * scale)\n",
    "#input_qt = QuantTensor(input_t, scale=torch.tensor(scale), bit_width=torch.tensor(8.0), signed=True)\n",
    "#bo.export_finn_onnx(VGG10, export_path=export_model_filename, input_t=input_qt)\n",
    "\n",
    "print(\"Model saved to %s\" % export_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20731bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'models/VGG10exp_2d_w4a4_v2_export.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5749440e20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(export_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-aspect",
   "metadata": {},
   "source": [
    "# Network surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "handy-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input quant thresholds\n",
      "[[-1.9921875 -1.9765625 -1.9609375 -1.9453125 -1.9296875 -1.9140625\n",
      "  -1.8984375 -1.8828125 -1.8671875 -1.8515625 -1.8359375 -1.8203125\n",
      "  -1.8046875 -1.7890625 -1.7734375 -1.7578125 -1.7421875 -1.7265625\n",
      "  -1.7109375 -1.6953125 -1.6796875 -1.6640625 -1.6484375 -1.6328125\n",
      "  -1.6171875 -1.6015625 -1.5859375 -1.5703125 -1.5546875 -1.5390625\n",
      "  -1.5234375 -1.5078125 -1.4921875 -1.4765625 -1.4609375 -1.4453125\n",
      "  -1.4296875 -1.4140625 -1.3984375 -1.3828125 -1.3671875 -1.3515625\n",
      "  -1.3359375 -1.3203125 -1.3046875 -1.2890625 -1.2734375 -1.2578125\n",
      "  -1.2421875 -1.2265625 -1.2109375 -1.1953125 -1.1796875 -1.1640625\n",
      "  -1.1484375 -1.1328125 -1.1171875 -1.1015625 -1.0859375 -1.0703125\n",
      "  -1.0546875 -1.0390625 -1.0234375 -1.0078125 -0.9921875 -0.9765625\n",
      "  -0.9609375 -0.9453125 -0.9296875 -0.9140625 -0.8984375 -0.8828125\n",
      "  -0.8671875 -0.8515625 -0.8359375 -0.8203125 -0.8046875 -0.7890625\n",
      "  -0.7734375 -0.7578125 -0.7421875 -0.7265625 -0.7109375 -0.6953125\n",
      "  -0.6796875 -0.6640625 -0.6484375 -0.6328125 -0.6171875 -0.6015625\n",
      "  -0.5859375 -0.5703125 -0.5546875 -0.5390625 -0.5234375 -0.5078125\n",
      "  -0.4921875 -0.4765625 -0.4609375 -0.4453125 -0.4296875 -0.4140625\n",
      "  -0.3984375 -0.3828125 -0.3671875 -0.3515625 -0.3359375 -0.3203125\n",
      "  -0.3046875 -0.2890625 -0.2734375 -0.2578125 -0.2421875 -0.2265625\n",
      "  -0.2109375 -0.1953125 -0.1796875 -0.1640625 -0.1484375 -0.1328125\n",
      "  -0.1171875 -0.1015625 -0.0859375 -0.0703125 -0.0546875 -0.0390625\n",
      "  -0.0234375 -0.0078125  0.0078125  0.0234375  0.0390625  0.0546875\n",
      "   0.0703125  0.0859375  0.1015625  0.1171875  0.1328125  0.1484375\n",
      "   0.1640625  0.1796875  0.1953125  0.2109375  0.2265625  0.2421875\n",
      "   0.2578125  0.2734375  0.2890625  0.3046875  0.3203125  0.3359375\n",
      "   0.3515625  0.3671875  0.3828125  0.3984375  0.4140625  0.4296875\n",
      "   0.4453125  0.4609375  0.4765625  0.4921875  0.5078125  0.5234375\n",
      "   0.5390625  0.5546875  0.5703125  0.5859375  0.6015625  0.6171875\n",
      "   0.6328125  0.6484375  0.6640625  0.6796875  0.6953125  0.7109375\n",
      "   0.7265625  0.7421875  0.7578125  0.7734375  0.7890625  0.8046875\n",
      "   0.8203125  0.8359375  0.8515625  0.8671875  0.8828125  0.8984375\n",
      "   0.9140625  0.9296875  0.9453125  0.9609375  0.9765625  0.9921875\n",
      "   1.0078125  1.0234375  1.0390625  1.0546875  1.0703125  1.0859375\n",
      "   1.1015625  1.1171875  1.1328125  1.1484375  1.1640625  1.1796875\n",
      "   1.1953125  1.2109375  1.2265625  1.2421875  1.2578125  1.2734375\n",
      "   1.2890625  1.3046875  1.3203125  1.3359375  1.3515625  1.3671875\n",
      "   1.3828125  1.3984375  1.4140625  1.4296875  1.4453125  1.4609375\n",
      "   1.4765625  1.4921875  1.5078125  1.5234375  1.5390625  1.5546875\n",
      "   1.5703125  1.5859375  1.6015625  1.6171875  1.6328125  1.6484375\n",
      "   1.6640625  1.6796875  1.6953125  1.7109375  1.7265625  1.7421875\n",
      "   1.7578125  1.7734375  1.7890625  1.8046875  1.8203125  1.8359375\n",
      "   1.8515625  1.8671875  1.8828125  1.8984375  1.9140625  1.9296875\n",
      "   1.9453125  1.9609375  1.9765625]\n",
      " [-1.9921875 -1.9765625 -1.9609375 -1.9453125 -1.9296875 -1.9140625\n",
      "  -1.8984375 -1.8828125 -1.8671875 -1.8515625 -1.8359375 -1.8203125\n",
      "  -1.8046875 -1.7890625 -1.7734375 -1.7578125 -1.7421875 -1.7265625\n",
      "  -1.7109375 -1.6953125 -1.6796875 -1.6640625 -1.6484375 -1.6328125\n",
      "  -1.6171875 -1.6015625 -1.5859375 -1.5703125 -1.5546875 -1.5390625\n",
      "  -1.5234375 -1.5078125 -1.4921875 -1.4765625 -1.4609375 -1.4453125\n",
      "  -1.4296875 -1.4140625 -1.3984375 -1.3828125 -1.3671875 -1.3515625\n",
      "  -1.3359375 -1.3203125 -1.3046875 -1.2890625 -1.2734375 -1.2578125\n",
      "  -1.2421875 -1.2265625 -1.2109375 -1.1953125 -1.1796875 -1.1640625\n",
      "  -1.1484375 -1.1328125 -1.1171875 -1.1015625 -1.0859375 -1.0703125\n",
      "  -1.0546875 -1.0390625 -1.0234375 -1.0078125 -0.9921875 -0.9765625\n",
      "  -0.9609375 -0.9453125 -0.9296875 -0.9140625 -0.8984375 -0.8828125\n",
      "  -0.8671875 -0.8515625 -0.8359375 -0.8203125 -0.8046875 -0.7890625\n",
      "  -0.7734375 -0.7578125 -0.7421875 -0.7265625 -0.7109375 -0.6953125\n",
      "  -0.6796875 -0.6640625 -0.6484375 -0.6328125 -0.6171875 -0.6015625\n",
      "  -0.5859375 -0.5703125 -0.5546875 -0.5390625 -0.5234375 -0.5078125\n",
      "  -0.4921875 -0.4765625 -0.4609375 -0.4453125 -0.4296875 -0.4140625\n",
      "  -0.3984375 -0.3828125 -0.3671875 -0.3515625 -0.3359375 -0.3203125\n",
      "  -0.3046875 -0.2890625 -0.2734375 -0.2578125 -0.2421875 -0.2265625\n",
      "  -0.2109375 -0.1953125 -0.1796875 -0.1640625 -0.1484375 -0.1328125\n",
      "  -0.1171875 -0.1015625 -0.0859375 -0.0703125 -0.0546875 -0.0390625\n",
      "  -0.0234375 -0.0078125  0.0078125  0.0234375  0.0390625  0.0546875\n",
      "   0.0703125  0.0859375  0.1015625  0.1171875  0.1328125  0.1484375\n",
      "   0.1640625  0.1796875  0.1953125  0.2109375  0.2265625  0.2421875\n",
      "   0.2578125  0.2734375  0.2890625  0.3046875  0.3203125  0.3359375\n",
      "   0.3515625  0.3671875  0.3828125  0.3984375  0.4140625  0.4296875\n",
      "   0.4453125  0.4609375  0.4765625  0.4921875  0.5078125  0.5234375\n",
      "   0.5390625  0.5546875  0.5703125  0.5859375  0.6015625  0.6171875\n",
      "   0.6328125  0.6484375  0.6640625  0.6796875  0.6953125  0.7109375\n",
      "   0.7265625  0.7421875  0.7578125  0.7734375  0.7890625  0.8046875\n",
      "   0.8203125  0.8359375  0.8515625  0.8671875  0.8828125  0.8984375\n",
      "   0.9140625  0.9296875  0.9453125  0.9609375  0.9765625  0.9921875\n",
      "   1.0078125  1.0234375  1.0390625  1.0546875  1.0703125  1.0859375\n",
      "   1.1015625  1.1171875  1.1328125  1.1484375  1.1640625  1.1796875\n",
      "   1.1953125  1.2109375  1.2265625  1.2421875  1.2578125  1.2734375\n",
      "   1.2890625  1.3046875  1.3203125  1.3359375  1.3515625  1.3671875\n",
      "   1.3828125  1.3984375  1.4140625  1.4296875  1.4453125  1.4609375\n",
      "   1.4765625  1.4921875  1.5078125  1.5234375  1.5390625  1.5546875\n",
      "   1.5703125  1.5859375  1.6015625  1.6171875  1.6328125  1.6484375\n",
      "   1.6640625  1.6796875  1.6953125  1.7109375  1.7265625  1.7421875\n",
      "   1.7578125  1.7734375  1.7890625  1.8046875  1.8203125  1.8359375\n",
      "   1.8515625  1.8671875  1.8828125  1.8984375  1.9140625  1.9296875\n",
      "   1.9453125  1.9609375  1.9765625]]\n",
      "Input tensor name: Add_0_out0\n",
      "Input tensor shape: [1, 2, 1024]\n",
      "Input tensor datatype: INT8\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import TensorProto, helper\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "\n",
    "finn_model = ModelWrapper(export_model_filename)\n",
    "\n",
    "# tidy up\n",
    "finn_model = finn_model.transform(InferShapes())\n",
    "finn_model = finn_model.transform(InferDataTypes())\n",
    "finn_model = finn_model.transform(GiveUniqueNodeNames())\n",
    "finn_model = finn_model.transform(GiveReadableTensorNames())\n",
    "finn_model.cleanup()\n",
    "\n",
    "# remove redundant value_info for primary input/output\n",
    "# othwerwise, newer FINN versions will not accept the model\n",
    "if finn_model.graph.input[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.input[0])\n",
    "if finn_model.graph.output[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.output[0])\n",
    "\n",
    "# extract input quantization thresholds for sw-based quantization\n",
    "input_mt_node = finn_model.get_nodes_by_op_type(\"MultiThreshold\")[0]\n",
    "input_mt_thresholds = finn_model.get_initializer(input_mt_node.input[1])\n",
    "print(\"input quant thresholds\")\n",
    "print(input_mt_thresholds)\n",
    "\n",
    "# preprocessing: remove input reshape/quantization from graph\n",
    "new_input_node = finn_model.get_nodes_by_op_type(\"Mul\")[0]\n",
    "new_input_tensor = finn_model.get_tensor_valueinfo(new_input_node.input[0])\n",
    "old_input_tensor = finn_model.graph.input[0]\n",
    "finn_model.graph.input.remove(old_input_tensor)\n",
    "finn_model.graph.input.append(new_input_tensor)\n",
    "new_input_index = finn_model.get_node_index(new_input_node)\n",
    "del finn_model.graph.node[0:new_input_index]\n",
    "\n",
    "# postprocessing: remove final softmax node from training\n",
    "softmax_node = finn_model.graph.node[-1]\n",
    "softmax_in_tensor = finn_model.get_tensor_valueinfo(softmax_node.input[0])\n",
    "softmax_out_tensor = finn_model.get_tensor_valueinfo(softmax_node.output[0])\n",
    "finn_model.graph.output.remove(softmax_out_tensor)\n",
    "finn_model.graph.output.append(softmax_in_tensor)\n",
    "finn_model.graph.node.remove(softmax_node)\n",
    "\n",
    "# remove redundant value_info for primary input/output\n",
    "# othwerwise, newer FINN versions will not accept the model\n",
    "if finn_model.graph.input[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.input[0])\n",
    "if finn_model.graph.output[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.output[0])\n",
    "\n",
    "# insert topK node in its place\n",
    "finn_model = finn_model.transform(InsertTopK(k=1))\n",
    "\n",
    "# manually set input datatype (not done by brevitas yet)\n",
    "finnonnx_in_tensor_name = finn_model.graph.input[0].name\n",
    "finnonnx_model_in_shape = finn_model.get_tensor_shape(finnonnx_in_tensor_name)\n",
    "finn_model.set_tensor_datatype(finnonnx_in_tensor_name, DataType[\"INT8\"])\n",
    "print(\"Input tensor name: %s\" % finnonnx_in_tensor_name)\n",
    "print(\"Input tensor shape: %s\" % str(finnonnx_model_in_shape))\n",
    "print(\"Input tensor datatype: %s\" % str(finn_model.get_tensor_datatype(finnonnx_in_tensor_name)))\n",
    "\n",
    "finn_model.save(ready_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ec62ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'models/18_VGG10_w4a4w4a3_v2_ready.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe1720ea190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(ready_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-forum",
   "metadata": {},
   "source": [
    "# FINN build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sufficient-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from VGG10_ready.onnx\n",
      "Intermediate outputs will be generated in /home/felixj/tmp_finn\n",
      "Final outputs will be generated in build_end2end_ZCU102\n",
      "Build log is at build_end2end_ZCU102/build_dataflow.log\n",
      "Running step: step_tidy_up [1/17]\n",
      "Running step: step_convert_1d_conv [2/17]\n",
      "Running step: step_streamline [3/17]\n",
      "Running step: step_convert_to_hls [4/17]\n",
      "Running step: step_create_dataflow_partition [5/17]\n",
      "Running step: step_target_fps_parallelization [6/17]\n",
      "Running step: step_apply_folding_config [7/17]\n",
      "Running step: step_generate_estimate_reports [8/17]\n",
      "Running step: step_hls_codegen [9/17]\n",
      "Running step: step_hls_ipgen [10/17]\n",
      "Running step: step_set_fifo_depths [11/17]\n",
      "Running step: step_create_stitched_ip [12/17]\n",
      "Running step: step_measure_rtlsim_performance [13/17]\n",
      "Running step: step_out_of_context_synthesis [14/17]\n",
      "Running step: step_synthesize_bitfile [15/17]\n",
      "Running step: step_make_pynq_driver [16/17]\n",
      "Running step: step_deployment_package [17/17]\n",
      "Completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "ready_model_filename = \"VGG10_ready.onnx\"\n",
    "\n",
    "def step_convert_1d_conv(model: ModelWrapper, cfg: build_cfg):\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "    return model\n",
    "\n",
    "steps = [\n",
    "        \"step_tidy_up\",\n",
    "        step_convert_1d_conv,\n",
    "        \"step_streamline\",\n",
    "        \"step_convert_to_hls\",\n",
    "        \"step_create_dataflow_partition\",\n",
    "        \"step_target_fps_parallelization\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_generate_estimate_reports\",\n",
    "        \"step_hls_codegen\",\n",
    "        \"step_hls_ipgen\",\n",
    "        \"step_set_fifo_depths\",\n",
    "        \"step_create_stitched_ip\",\n",
    "        \"step_measure_rtlsim_performance\",\n",
    "        \"step_out_of_context_synthesis\",\n",
    "        \"step_synthesize_bitfile\",\n",
    "        \"step_make_pynq_driver\",\n",
    "        \"step_deployment_package\",\n",
    "    ]\n",
    "\n",
    "cfg = build_cfg.DataflowBuildConfig(\n",
    "        steps=steps,\n",
    "        output_dir=\"build_end2end_ZCU102\",\n",
    "        board=\"ZCU102\",\n",
    "        synth_clk_period_ns=5.0,\n",
    "        folding_config_file=\"folding_config/ZCU102_folding_config.json\",\n",
    "        #target_fps=1000000,\n",
    "        #mvau_wwidth_max=128,\n",
    "        auto_fifo_depths=True,\n",
    "        shell_flow_type=build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "        vitis_platform=None,\n",
    "        # enable extra performance optimizations (physopt)\n",
    "        vitis_opt_strategy=build_cfg.VitisOptStrategyCfg.PERFORMANCE_BEST,\n",
    "        generate_outputs=[\n",
    "            build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "            build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "            build_cfg.DataflowOutputType.BITFILE,\n",
    "            build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "#build.build_dataflow_cfg(ready_model_filename, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f890e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to regular ONNX for TensorRT\n",
    "import torch.onnx\n",
    "\n",
    "batch_sizes = [1, 4, 8, 32, 64, 128, 1024, 4096]\n",
    "for batch_size in batch_sizes:\n",
    "    export_model_filename = \"models/\" + model_name + \"_\" + str(batch_size) + \"_export.onnx\"\n",
    "    dummy_input=torch.randn(batch_size, 2, 1024)\n",
    "    torch.onnx.export(model.cpu(), dummy_input, export_model_filename, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127211e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
